{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Evaluation\n",
    "In order to contextualize the performance of the baselines (general and specific), we want to check how often the key search (with the given fuzziness) yields any result. In case of the general baseline, if no match is found then no key-value is extracted, in case of the specific baseline there is the addition of synonyms for some of the keys which increases the likelihood of finding a key in the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_csv(\"datasets/kleister_charity/dev-0/in_extended.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_key_to_gold_key = {\n",
    "    \"Address (post code)\": \"address__postcode\",\n",
    "    \"Address (street)\": \"address__street_line\",\n",
    "    \"Address (post town)\": \"address__post_town\",\n",
    "    \"Charity Name\": \"charity_name\",\n",
    "    \"Charity Number\": \"charity_number\",\n",
    "    \"Annual Income\": \"income_annually_in_british_pounds\",\n",
    "    \"Period End Date\": \"report_date\",\n",
    "    \"Annual Spending\": \"spending_annually_in_british_pounds\",\n",
    "}\n",
    "prompt_keys = list(prompt_key_to_gold_key.keys())\n",
    "gold_keys = list(prompt_key_to_gold_key.values())\n",
    "\n",
    "# for specific baseline we also use these synonyms\n",
    "synonyms = {\n",
    "    \"Charity Name\": [\"Charity Name\"],\n",
    "    \"Charity Number\": [\n",
    "        \"Charity Number\",\n",
    "        \"Charity Registration No\",\n",
    "        \"Charity No\",\n",
    "    ],\n",
    "    \"Annual Income\": [\"Annual Income\", \"Income\", \"Total Income\"],\n",
    "    \"Period End Date\": [\"Period End Date\", \"Period End\", \"Year Ended\"],\n",
    "    \"Annual Spending\": [\n",
    "        \"Annual Spending\",\n",
    "        \"Spending\",\n",
    "        \"Total Spending\",\n",
    "        \"Expenditure\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create dict that will record how often the respective key was actually found\n",
    "key_to_count = {key: 0 for key in prompt_keys}\n",
    "\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this has to match the respective configuration of the baseline model that is evaluated\n",
    "type_of_baseline = \"specific\" # or \"specific\" \n",
    "error_percentage = 0.18\n",
    "\n",
    "def get_best_match_span(text: str, key: str):\n",
    "    \"\"\"\n",
    "    Returns the best match for the key in the text with some fuzziness\n",
    "    (i.e. we limit the levenshtein distance) of the best match.\n",
    "\n",
    "    (?b) -> BESTMATCH\n",
    "    (?i) -> IGNORECASE\n",
    "    {e<n} -> up to n errors (subs, inserts, dels). if more -> None\n",
    "    (1) -> the span of the best match\n",
    "    \"\"\"\n",
    "    key_length = len(key)\n",
    "    max_errors = round(key_length * error_percentage)\n",
    "    match_span = regex.search(f\"(?b)(?i)({key}){{e<{max_errors}}}\", text)\n",
    "\n",
    "    if match_span:\n",
    "        return match_span.span(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(in_df)):\n",
    "    text = in_df.loc[in_df[\"filename\"] == in_df.iloc[i][\"filename\"], \"text_best_cleaned\"].values[0]\n",
    "\n",
    "    if type_of_baseline == \"general\":\n",
    "        # check for a match for each key\n",
    "        for i, key in enumerate(prompt_keys):\n",
    "            total += 1\n",
    "            match_span = get_best_match_span(text, key)\n",
    "\n",
    "            if match_span is None:\n",
    "                continue\n",
    "            else:\n",
    "                key_to_count[key] += 1\n",
    "    \n",
    "    elif type_of_baseline == \"specific\":\n",
    "        # check for a match for each synonym\n",
    "        for i, key in enumerate(list(synonyms.keys())):\n",
    "            total += 1\n",
    "            for synonym in synonyms[key]:\n",
    "                match_span = get_best_match_span(text, synonym)\n",
    "    \n",
    "                if match_span is None: # no match for this synonym\n",
    "                    continue\n",
    "                else:\n",
    "                    key_to_count[key] += 1 # found a match for this key\n",
    "                    break # no need to check the other synonyms for this key as we are only interested if any of them matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Charity Name': 22.499999999999996, 'Charity Number': 97.72727272727273, 'Annual Income': 97.72727272727273, 'Period End Date': 97.50000000000001, 'Annual Spending': 94.0909090909091}\n",
      "(macro)[over keys] average Percentage of how often the keys can be found in the docoument: 81.90909090909092\n",
      "(micro)[over all predictions] average Percentage of how often the keys can be found in the document: 81.9090909090909\n"
     ]
    }
   ],
   "source": [
    "if type_of_baseline == \"specific\":\n",
    "    num_keys_considered = len(synonyms.keys())\n",
    "\n",
    "    # remove the keys that we don't use synonyms for\n",
    "    for key in prompt_keys:\n",
    "        if key not in synonyms.keys():\n",
    "            key_to_count.pop(key)\n",
    "else:\n",
    "    num_keys_considered = len(prompt_keys)\n",
    "\n",
    "\n",
    "key_to_count_percentage = {key: count / total * num_keys_considered * 100 for key, count in key_to_count.items()}\n",
    "print(key_to_count_percentage)\n",
    "\n",
    "# macro average\n",
    "print(f\"(macro)[over keys] average Percentage of how often the keys can be found in the docoument: {sum(key_to_count_percentage.values()) / len(key_to_count_percentage)}\")\n",
    "\n",
    "# micro average\n",
    "print(f\"(micro)[over all predictions] average Percentage of how often the keys can be found in the document: {sum(key_to_count.values()) / total * 100}\")\n",
    "\n",
    "# they are the same which makes sense because all classes (keys) are checked the same amount of times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('uni-kie-JrmAaldC-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cec8707b55c29234c829cd46c92f0adfa2b741d49905cfffb1cd22fea1c1c224"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
